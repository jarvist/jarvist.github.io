<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jarvist Moore Frost: Academic blog</title>
    <link>http://jarvist.github.io/post/index.xml</link>
    <description>Recent content in Posts on Jarvist Moore Frost: Academic blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-GB</language>
    <lastBuildDate>Wed, 04 Jan 2017 12:29:00 +0000</lastBuildDate>
    <atom:link href="http://jarvist.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>ICL Bookclub</title>
      <link>http://jarvist.github.io/post/2017-01-04-icl-bookclub/</link>
      <pubDate>Wed, 04 Jan 2017 12:29:00 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/2017-01-04-icl-bookclub/</guid>
      <description>&lt;p&gt;Now that the Walsh group has a critical mass at Imperial College London, I am
planning to restart the Bookclub.&lt;/p&gt;

&lt;p&gt;Keith Butler kicked these off in Bath with the guiding words of everyone&amp;rsquo;s
favourite German pessimist, Arthur Schopenhauer:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Buying books would be a good thing if one could also buy the time to read
 them in: but as a rule the purchase of books is mistaken for the
 appropriation of their contents.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The plan is to do some reading &amp;amp; self-directed study of a relevant book, and
then get together at &lt;strong&gt;5PM on Thursdays&lt;/strong&gt; (in weeks when there is not an
interesting TYC seminar) to discuss and explain things to each other.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re going to start with the first one and a half chapters of Ziman&amp;rsquo;s
solid-state book &amp;ldquo;Principles of the theory of solids&amp;rdquo;, ideally the second
edition (1971).
( There is currently 1 copy of the 2nd edition, and 3 copies of the 1st
edition, available for loan at the Central Library, Level 4 (530.41 ZIM).)&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s Chapter 1: Periodic structures, reciprocal lattice, Bloch&amp;rsquo;s theorem,
Brillouin zone; and Chapter 2: Lattice Waves: Lattice dynamics, lattice sums
(Ewald), lattice specific heat and lattice spectrum (DoS). So stopping before
the diffraction + Debye waller + phonon scattering, in the second half of the
second chapter.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll get together to discuss this at 5PM on Thursday 12th January, &lt;strong&gt;floor two
of the RSM (Dept Materials), Imperial College London.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Other books which we are planning to visit in the near future are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Martin&amp;rsquo;s DFT book&lt;/li&gt;
&lt;li&gt;Krauth&amp;rsquo;s Stat. Mech. - Algo and Computation&lt;/li&gt;
&lt;li&gt;Tinkham&amp;rsquo;s Group Theory and Quantum Mechanics&lt;/li&gt;
&lt;li&gt;Feynman&amp;rsquo;s Statistical Mechanics&lt;/li&gt;
&lt;li&gt;Nye&amp;rsquo;s Physical Properties of Materials by Tensors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Everybody welcome! You certainly don&amp;rsquo;t need to do DFT to be able to, or to
benefit from, knowing the theory. (Arguably doing calculations actually gets in
the way&amp;hellip;)&lt;/p&gt;

&lt;p&gt;We have a discussion channel on our &amp;ldquo;Materials Discovery Network&amp;rdquo; Slack group.
&lt;a href=&#34;https://mdn-uk.slack.com/messages/icl-bookclub/&#34;&gt;https://mdn-uk.slack.com/messages/icl-bookclub/&lt;/a&gt;
It&amp;rsquo;s on the &amp;lsquo;free&amp;rsquo; plan, so messages are ephemeral, but all friendly electronic structure people very welcome!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Constrained geometry optimisation in Gaussian</title>
      <link>http://jarvist.github.io/post/2016-10-13-constrained-geometry-optimisation-in-gaussian/</link>
      <pubDate>Thu, 13 Oct 2016 11:29:00 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-10-13-constrained-geometry-optimisation-in-gaussian/</guid>
      <description>&lt;p&gt;&lt;em&gt;Summary&lt;/em&gt;: If you want to do a geometry relaxation around a constrained degree of
freedom (bond length, angle, dihedral, etc.) in Gaussian 09, you need two
&amp;lsquo;ModRedundant&amp;rsquo; specifications, one to &lt;code&gt;B&lt;/code&gt;uild in the coordinate with the value
you set, the next to then &lt;code&gt;F&lt;/code&gt;reeze this coordinate so that it is constrained
during the optimisation.&lt;/p&gt;

&lt;p&gt;Here is an example for Biphenyl, setting the torsional angle to 90 degrees
(making the phenyls orthogonal).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#p opt=ModRedundant am1

Biphenyl ModRedundant - Minimalist working constrained optimisation

0 1
C                 -4.41584965    0.94482757    0.00000000
C                 -3.02068965    0.94482757    0.00000000
C                 -2.32315165    2.15257857    0.00000000
C                 -3.02080565    3.36108757   -0.00119900
C                 -4.41563065    3.36100957   -0.00167800
C                 -5.11323165    2.15280357   -0.00068200
H                 -4.96560865   -0.00748943    0.00045000
H                 -2.47118165   -0.00768543    0.00131500
H                 -2.47060565    4.31323057   -0.00125800
H                 -4.96575265    4.31329057   -0.00263100
H                 -6.21283565    2.15298657   -0.00086200
C                 -0.78315191    2.15269060    0.00088786
C                 -0.08606526    3.36121931    0.00088734
C                 -0.08548693    0.94501548    0.00335961
C                  1.30876256    3.36175187    0.00267704
H                 -0.63630428    4.31325796   -0.00061165
C                  1.30993941    0.94551682    0.00463341
H                 -0.63486990   -0.00759907    0.00399419
C                  2.00679196    2.15379382    0.00415373
H                  1.85833456    4.31416964    0.00249700
H                  1.85980667   -0.00681651    0.00652304
H                  3.10655225    2.15452197    0.00514924

2       3       12      13      =90.0       B
2       3       12      13      F

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Longer Version&lt;/em&gt;:
Doing a constrained geometry optimisation is a common necessity when modelling
organic electronics.
A particular occurrence is wanting to set the backbone-torsion (the dihedral) of
an oligomer fragment (representing a polymer).
This can be due to the fact that structural measurements show a particular
packing motif, and you want to override the behaviour of your quantum
chemistry, or you are interested in studying something (transfer integral, HOMO
/ LUMO energy, potential energy) as a function of the rotation.&lt;/p&gt;

&lt;p&gt;The relevant &lt;code&gt;ModRedundant&lt;/code&gt; part of the Gaussian manual
(&lt;a href=&#34;http://www.gaussian.com/g_tech/g_ur/k_opt.htm&#34;&gt;http://www.gaussian.com/g_tech/g_ur/k_opt.htm&lt;/a&gt;) is at best confusing.&lt;/p&gt;

&lt;p&gt;If you want a single job that scans along a coordinate, you can use &lt;code&gt;S&lt;/code&gt; for
Scan. However, this has some issues: you end up with all the intermediate
geometries buried in a massive .log file; you can&amp;rsquo;t parallelise the geometry
optimisations; you can get some weird effects from steric hindrance, so should
really do the scans in the two different directions to detect any &amp;lsquo;clicking&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;So being able to &lt;code&gt;F&lt;/code&gt;reeze in a constraint is really useful, so that you can
then have a load of &lt;code&gt;.com&lt;/code&gt; files named &lt;code&gt;000.com&lt;/code&gt;, &lt;code&gt;010.com&lt;/code&gt; etc. for the angle
along the coordinate.
These are then trivial to use in further processing by i.e. something like
(&lt;a href=&#34;https://github.com/jarvist/hpc-bin/blob/master/jkp_extract_geom.awk&#34;&gt;https://github.com/jarvist/hpc-bin/blob/master/jkp_extract_geom.awk&lt;/a&gt;) to
extract all the optimised geometries into new &lt;code&gt;.com&lt;/code&gt; files, to do single point
calculations.&lt;/p&gt;

&lt;p&gt;So that&amp;rsquo;s grand; from 2007 to 2012 I had been using &lt;code&gt;opt=ModRedundant&lt;/code&gt; with
a single &lt;code&gt;Freeze&lt;/code&gt; line after the atom specification, to do a constrained
geometry optimisation.
Then sometime around &lt;code&gt;G09.B&lt;/code&gt;, this stopped working!
The jobs would run, but all geometries would optimise to their relaxed
configurations.
I didn&amp;rsquo;t really understand why this occurred; it was immensely frustrating.
As a work-around I used the old versions of Gaussian to do geometry
optimisations.&lt;/p&gt;

&lt;p&gt;My student was recently bitten by this bug (my fault - as I sent her one of my
&amp;lsquo;working&amp;rsquo; files from circa. 2008!).
So we investigated properly, and eventually found out the reason.
If you have a single &lt;code&gt;F&lt;/code&gt; line such as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2       3       12      13      =90.0       F
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and then go and look for the relevant part in the output &lt;code&gt;.log&lt;/code&gt; file, you will
find that the ModRedundant section echoes back:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The following ModRedundant input section has been read:
D       2       3      12      13 90.000 B
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wait a second - that&amp;rsquo;s a B! I told you F!
So therein lies the rub.
Gaussian, if you specify &lt;code&gt;F&lt;/code&gt;reeze alongside specifying a value to set the
constrained coordinate to, it will silently rewrite this to &lt;code&gt;B&lt;/code&gt;uild, and so set
that coordinate for the initial optimisation, but then relax away from that
coordinate.
Previously a single line with &lt;code&gt;F&lt;/code&gt; specifying the coordinate, set the
constraint, and froze it.&lt;/p&gt;

&lt;p&gt;Another curiosity which I do not understand, is that you can&amp;rsquo;t seem to do
a constrained geometry optimisation with a empirical potential (such as &lt;code&gt;UFF&lt;/code&gt;)
in the above.&lt;br /&gt;
Maybe it uses different optimisation routines (i.e. Cartesian)?&lt;/p&gt;

&lt;p&gt;All in all, the new behaviour is perhaps more logical.&lt;br /&gt;
Essentially Gaussian is now doing something different when encountering
undefined behaviour.
Internally I would guess there&amp;rsquo;s some absolute horror show of a series of
Fortran routines messing around with internal variables based on this flags,
rather than a sensible parser.
It just always feels that when someone breaks something you had working
previously, that they are working against you!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Soft Mode Tunnelling</title>
      <link>http://jarvist.github.io/post/2016-07-14-Soft-Mode-Tunnelling/</link>
      <pubDate>Thu, 14 Jul 2016 20:00:00 +0100</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-07-14-Soft-Mode-Tunnelling/</guid>
      <description>&lt;!-- MathJax --&gt;

&lt;script type=&#34;text/javascript&#34;
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;If we consider the Mexican Hat potential discussed in the previous blog post,
as a stand in for a soft phonon mode, a fundamental question in
chemical physics is how regularly the mode tunnels between the vibrational
states localised on one side, versus the other.&lt;/p&gt;

&lt;p&gt;Classically, the chance of crossing over is zero, unless you have sufficient
energy to overtop the barrier.
From a Statistical Physics point of view, at finite temperature, some states
will be Boltzmann populated with sufficient energy, and from this fraction and
an attempt frequency from the rate of oscillation within an individual well,
you could approximate the classical rate.
You could directly extract this rate from a Molecular Dynamics simulation,
including anharmonic and correlation terms, but even with &lt;em&gt;ab-initio&lt;/em&gt; molecular
dynamics, your nuclear coordinate is classical.&lt;/p&gt;

&lt;p&gt;However, there is, of course, also quantum mechanical tunnelling directly
through the barrier.
The boss (&lt;a href=&#34;https://twitter.com/lonepair&#34;&gt;@lonepair&lt;/a&gt;) asked me to consider
whether this rate was easily calculable, to complement the considerable
soft-phonon work occurring in the group.&lt;/p&gt;

&lt;p&gt;To calculate this rate, there are a number of different approaches you could
take.
This includes semi-classical WKB theory, and methods used in small polaron hopping.&lt;br /&gt;
Here I start with a very general analytic quantum mechanical analysis, which
seems to to give you a very nice and general result to then use with your
numeric method.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;../../images/2016-07-14-SoftWell.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Mexican Hat confined modes&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;If we look at the states (\(\Psi_n\)) localised in the wells, you can see
that the first state is symmetric, and the then the second state is
anti-symmetric. The Pauli exclusion principle leads to a slight splitting in
the degeneracy.&lt;/p&gt;

&lt;p&gt;Our Hamiltonian is time independent, which means that we can use our eigenstates as a basis
$$\Psi_n(Q,t) = \Psi_n(Q).e^{-i \omega_n t}$$&lt;/p&gt;

&lt;p&gt;As expected, the time-dependence of this wavefunction just leads to a phase term (entirely imaginary dependence on \(t\)), as the \(\Psi_n\) are eigenstates of a time-independent Hamiltonian. The states will just beat at a characteristic frequency.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s construct a wavepacket of \(\Psi_1\) and \(\Psi_2\).&lt;/p&gt;

&lt;p&gt;$$\Phi(Q,t)=\frac{1}{\sqrt{2}} \left( \Psi_1(Q,t) + \Psi_2(Q,t)  \right)$$&lt;/p&gt;

&lt;p&gt;Expand to our time-dependent form above,&lt;/p&gt;

&lt;p&gt;$$\Phi(Q,t)=\frac{1}{\sqrt{2}} \left( \Psi_1(Q).e^{-i \omega_1 t} + \Psi_2(Q).e^{-i \omega_2 t}  \right)$$&lt;/p&gt;

&lt;p&gt;Bring out the base frequency-beating term,&lt;/p&gt;

&lt;p&gt;$$\Phi(Q,t)=\frac{1}{\sqrt{2}} e^{-i \omega_1 t} \left( \Psi_1(Q) + \Psi_2(Q).e^{-i (\omega_2-\omega_1) t}  \right)$$&lt;/p&gt;

&lt;p&gt;The observable we are interested in is the location of the wavepacket.
We evaluate the probability density function by calculating the state&amp;rsquo;s
expectation value with the position operator&lt;/p&gt;

&lt;div&gt;
$$ 
\begin{align}
&lt; \Phi(Q,t) | \, \hat{X} \, | \Phi(Q,t &gt; &amp; =  \lvert\Phi(Q,t)\rvert^2 = \Phi(Q,t) \; \Phi^{\ast}(Q,t)
\\
&amp; = \frac{1}{\sqrt{2}} e^{-i \omega_1 t} \left( \Psi_1(Q) + \Psi_2(Q).e^{-i (\omega_2-\omega_1) t}  \right) \frac{1}{\sqrt{2}} e^{+i \omega_1 t} \left( \Psi_1(Q) + \Psi_2(Q).e^{+i (\omega_2-\omega_1) t}  \right)
\\
&amp; = \frac{1}{2} \left( \Psi_1^2(Q) + \Psi_1(Q)\Psi_2(Q).e^{-i (\omega_2-\omega_1) t} + \Psi_2(Q)\Psi_1(Q).e^{+i (\omega_2-\omega_1)t} + \Psi_2^2(Q) \right) 
\end{align}
$$
&lt;/div&gt;

&lt;p&gt;Not 100% sure I got all the algebra correct there :^)
But the key thing is that the state is phasing between&lt;/p&gt;

&lt;p&gt;$$ \lvert\Psi_1\rangle \;\rightarrow\;
\lvert\Psi_1\Psi_2\rangle \;\rightarrow\;
\lvert\Psi_2\rangle \;\rightarrow\;
\lvert\Psi_2\Psi_1\rangle \;\circlearrowright$$&lt;/p&gt;

&lt;p&gt;The \(\Psi_1\) and \(\Psi_2\) states are de-localised between the two wells,
but as these are Even and Odd wavefunctions, the combinations will be localised
in state 1 and state 2.&lt;/p&gt;

&lt;p&gt;And there&amp;rsquo;s only one, obvious, time constant generated by the phase term&lt;/p&gt;

&lt;p&gt;$$e^{-i (\omega_2-\omega_1) t}$$&lt;/p&gt;

&lt;p&gt;By Euler&amp;rsquo;s identity, \(e^{i\pi}=-1\)&lt;/p&gt;

&lt;p&gt;$$\tau=(\omega_2-\omega_1)/\pi$$&lt;/p&gt;

&lt;p&gt;By \(E=\hbar\omega , \omega=E/\hbar\), this is&lt;/p&gt;

&lt;p&gt;$$\tau = \frac{E_2-E_1}{\pi\hbar}$$&lt;/p&gt;

&lt;p&gt;So really quite trivial! The time constant of beating between the states
(tunnelling through the potential barrier) is directly related to the degeneracy
splitting of the states.
This makes sense as in the semi-classical picture, the degeneracy splitting is
linked to the magnitude of the transfer (wavefunction overlap) integral
between state 1 and 2.&lt;/p&gt;

&lt;p&gt;I was initially concerned that there was no mass term here&amp;mdash;obviously mass
should come into the time constant of tunnelling! But it is there, hidden in the
solution of the Time Independent Schr&amp;ouml;dinger Equation.&lt;/p&gt;

&lt;p&gt;For the potential + states above, the values are not so ridiculous&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;../../images/2016-07-14-TunnellingTimes.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Time to tunnel between states&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Classically, with a harmonic potential, you would have a Simple Harmonic
Oscillator with&lt;/p&gt;

&lt;p&gt;$$\tau=\frac{2\pi}{\omega}$$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$\omega=\sqrt{\frac{k}{m}}$$&lt;/p&gt;

&lt;p&gt;For this system at a finite temperature, we should be able to consider a
Bose-Einstein distribution of weights, and then collect an overall tunnelling
time constant by summing the weighted rates. I haven&amp;rsquo;t yet tried this.&lt;/p&gt;

&lt;p&gt;$$\tau_{total} = \left( \frac{p_1}{\tau_1} + \frac{p_2}{\tau_2} + \frac{p_3}{\tau_3} &amp;hellip; \right)^{-1} $$&lt;/p&gt;

&lt;p&gt;It was very enjoyable to find myself doing some basic pen + paper physics!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Electron Phonon Coupling with Soft Modes</title>
      <link>http://jarvist.github.io/post/2016-07-13-Electron-Phonon-Coupling-with-Soft-Modes/</link>
      <pubDate>Wed, 13 Jul 2016 20:00:00 +0100</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-07-13-Electron-Phonon-Coupling-with-Soft-Modes/</guid>
      <description>&lt;!-- MathJax --&gt;

&lt;script type=&#34;text/javascript&#34;
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;I&amp;rsquo;ve spent a lot of time over the last three years thinking about
electron-phonon coupling. Thinking, not doing, being the operative word, as
I&amp;rsquo;ve found the theory really quite a large mass to get my head around!&lt;/p&gt;

&lt;p&gt;Recently I saw my way in to something that seemed vaguely useful and
interesting. I&amp;rsquo;d put together a 1D Time-Independent-Schr&amp;ouml;dinger-Equation
solver, originally for my own amusement, then to show my second year Chemistry
tutees, then rebuilt for actual science.
It&amp;rsquo;s surprisingly easy - discretise space, place your potential energy on the
diagonal of a matrix, place a finite-difference approximation to the gradient
on the tridiagonal (the kinetic energy), and via an application of the
variational method this gives you a full set of eigenstates and eigenenergies
when you diagonalise the matrix.&lt;/p&gt;

&lt;p&gt;Seeing the workbook would be useful to follow the discussion in the rest of
this post:-
&lt;a href=&#34;https://github.com/jarvist/Julia-SoftModeTISH-DeformationPotential/blob/master/iJulia-Notebooks/2016-06_SoftMAPIModes_TISH_electron_phonon_coupling.ipynb&#34;&gt;iJuliaNotebook on Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The same method is just as applicable to an electron in an electrostatic
potential, or a nuclear degree of freedom in the potential energy of
a material.
If you have a harmonic potential, the resulting wavefunctions are Gaussian.
The most simple anharmonic potential you can imagine, while still being even
(retaining inversion crystal symmetry) is the biquadratic Mexican Hat
\(E(Q)=A.Q^2+B.Q^4\).&lt;/p&gt;

&lt;p&gt;With the Mexican Hat potential you get some important bits of undergraduate
quantum mechanics turning up. For instance, the isolated states in the two minima are
degenerate, but forced to adopt opposite parity forms by the Pauli exclusion
principle.&lt;/p&gt;

&lt;p&gt;So this is just in 1D, but we can consider this to be Q, a generalised reaction
coordinate within a Normal Mode of the motion of a material.
These Normal Modes come from the eigen decomposition of the Dynamic Matrix (a
set of second-order force constants).
These are what you get when within your favourite electronic structure package
you do a &amp;lsquo;phonon&amp;rsquo; calculation in a periodic solid, or a &amp;lsquo;frequency&amp;rsquo; calculation
in a molecule.
These modes form an orthogonal set; they are implicitly separated (in the
harmonic limit) and so can be considered independently.&lt;/p&gt;

&lt;p&gt;Our Mexican Hat potential is now a good model for a soft phonon mode, as seen
in a large class of materials, including important technological applications
in ferroelectrics.
The potential energy surface can be recovered by walking along the normal
eigenmode associated with an &amp;lsquo;imaginary&amp;rsquo; mode, the eigenvector pointing in the
direction of maximum curvature. I don&amp;rsquo;t know how accurate this is for soft
phonon modes, the motion is large and you are going in a straight line in
a direction derived from the local curvature.
The solution to this Schr&amp;ouml;dinger equation is the nuclear wavefunction for
this normal mode.&lt;/p&gt;

&lt;p&gt;But how this does this relate to electron-phonon coupling?
Most modern approaches to electron-phonon coupling are based on
density-functional-perturbation-theory.
As a perturbation theory, this only holds true for small variations around the
equilibrium geometry, i.e. you assume the range of motion is small, that the
material is stiff.
To evaluate coupling terms, you assume that the deformation
potential (how the electron energy varies as a function of distortion) is
quadratic, which allows the second order perturbation theory to pull out a well
defined value.&lt;/p&gt;

&lt;p&gt;Typically, the codes that calculate these parameters give up when detecting
a soft mode, giving a zero contribution.
In some cases this is likely to be missing the largest contribution, where the
large range of motion of a soft mode makes up the majority electron phonon
coupling.&lt;/p&gt;

&lt;p&gt;So to try and calculate this parameter, let us start by making the
Born-Oppenheimer approximation of separating the full wavefunction \(\Phi\)
into a product of electron \(\Psi\) and nuclear \(\chi\) parts, within the
(assumed independent) normal mode we are interested in, Q.&lt;/p&gt;

&lt;div&gt;
$$ \Phi(r,\,Q) = \Psi(r;\, Q) \, \chi(Q)$$
&lt;/div&gt;

&lt;p&gt;The nuclear \(\chi\) wavefunction depends only on the normal mode coordinate,
whereas the electron and full wavefunction depend (naturally!) on the electron
locations \(r\).&lt;/p&gt;

&lt;p&gt;By solving the nuclear wavefunction in the manner above, for a potential energy
surface derived by mode following, we have a set of vibrational eigenstates
which we can populate with a Bose-Einstein distribution. The sum of the
\(\Psi^2\)
contributions (normalised) gives us a probability density function for the
nuclear coordinates in this normal mode, as a function of temperature.&lt;/p&gt;

&lt;p&gt;The electronic structure we can solve (and offload all the pain of dealing with
the electrons!) by calculating, with the Born-Oppenheimer approximation (now
the frozen-phonon approximation), the
electron structure only along the same normal mode Q.
You use your favourite code to generate \(E_g(Q)\), a deformation potential
along a phonon mode Q.
This includes all the electron-electron interaction (to which we can add by
including exact electron exchange, and other electron correlation contributions).
By the assumptions used in perturbation electron-phonon calculations, you
expect this to be roughly quadratic around Q=0.
Following symmetry, for most modes in most crystals, it should be an even
expansion around Q=0.&lt;/p&gt;

&lt;p&gt;This assumes that the nuclear wavefunction does not mix into the full
electron+nuclear wavefunction, which is likely to be correct if you are considering
low-frequency (i.e. soft) nuclear motions.&lt;/p&gt;

&lt;p&gt;We can then get back to the temperature resolved electron-phonon
coupling for this mode by calculating the following integral:&lt;/p&gt;

&lt;div&gt;
$$ E_g(T) = \left&lt; \chi(Q,T) \,\rvert\, E_g(Q) \,\lvert\, \chi(Q,T) \right&gt; $$
&lt;/div&gt;

&lt;p&gt;This is trivial to evaluate in 1D, it&amp;rsquo;s just a matter of multiplying the
normalised probability density function for the Bose-Einstein occupied nuclear
wavefunction, by the deformation potential.&lt;/p&gt;

&lt;p&gt;So that&amp;rsquo;s grand.
A seemingly new and very simple method to calculate electron-phonon couplings
of soft modes (of which there are many many important technological examples).
The result is Temperature dependent, including the Zero Point Fluctuation.
(The quantum mechanical vibrational ground state is very different to the
classical prediction.)&lt;/p&gt;

&lt;p&gt;I am however much concerned by how easy it was, and that no one else seems to
have tried it yet!&lt;/p&gt;

&lt;p&gt;As a theory there are some nice features.
It has full vibrational wavefunctions, albeit they are treated in a mean-field
way when the electron-phonon interaction is calculated by only considering the
nuclear-wavefunction-density.
I would argue that by using a deformation-potential in Q, we are taking some kind of
zeroth-order approximation to the electron-phonon coupling.
As the physical range of motion for a soft mode is large, this might be fairly accurate.
For standard, harmonic, phonons, the contribution is tiny, and higher orders in
the electron-phonon interaction will dominate.&lt;/p&gt;

&lt;p&gt;A distinct drawback is that we&amp;rsquo;re currently evaluating for just one arbitrary
location in the vibrational Brillouin-Zone of the material. There&amp;rsquo;s an explicit
phase term (i.e. location in q-space) which is chosen to then generate
real-space distortions in Q to enable the calculation of the electronic
structure (and so both the electron deformation potential, and nuclear vibrational potential).
It is well known that the electron-phonon interaction should be
integrated across the full Brillouin-Zone in both vibrational (q) and
electronic (k) phase space, and that convergence of this summation is nasty as
the electronic-phonon coupling is very spiky.
I would argue that this method is still useful when you have a mode with
a known softness at one particular location in the Brillouin Zone;
with Bose-Einstein statistics, this soft mode will end up extremely highly
populated at room temperature (i.e. it makes up the majority of the thermal
motion of the crystal).&lt;/p&gt;

&lt;p&gt;I was slightly reassured  when reading this recent paper - Figure 4 seems to be
almost identical to what I am suggesting, just for a rather boring harmonic
example, and only considering the ground state, rather than a Bose-Einstein
ensemble. &lt;a href=&#34;http://dx.doi.org/10.1103/PhysRevB.92.085137&#34;&gt;Phys. Rev. B 92, 085137, 2015&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So I&amp;rsquo;m very interested if anyone out there has any thoughts to the validity or
otherwise of the above method. Probably it&amp;rsquo;s a terrible idea, guaranteed to
fail, or been done and discarded many years ago.
I finish on a cheery quote:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The previous methods for calculating the electron-phonon matrix element in
a metal are neither rigorously formulated nor satisfactory in their results.
From each method there is something to learn&amp;mdash;usually that the method is
unreliable in some important aspect.&amp;rdquo; Ziman, 1960 &amp;lsquo;Electrons and Phonons&amp;rsquo;,
&amp;sect; 5.7, page 197.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Useful references:
&lt;a href=&#34;http://dx.doi.org/10.1016/S0081-1947(08)60593-7&#34;&gt;Sham and Ziman, Solid State Physics Volume 15, 1963, Pages 221–298&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Royal Society 2015 URF Scheme - Lay Report</title>
      <link>http://jarvist.github.io/post/2016-07-13-RoyalSociety2015URF-LayReport/</link>
      <pubDate>Wed, 13 Jul 2016 16:00:00 +0100</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-07-13-RoyalSociety2015URF-LayReport/</guid>
      <description>

&lt;p&gt;I applied for the Royal Society University Research Fellowship scheme last
summer. I wasn&amp;rsquo;t successful (Boo). As part of the application, I wrote
a lay-person summary of my research project, limited to 3500 characters.&lt;/p&gt;

&lt;p&gt;There wasn&amp;rsquo;t much guidance as to who or what it was for, so I wrote it for
a typical imagined audience of A-level students.
I had quite a lot of fun writing it (certainly more fun that trying to get the
costings to add up&amp;hellip;), so I thought I may as well publish it here to avoid it
festering in some dark corner of my hard drive.&lt;/p&gt;

&lt;h2 id=&#34;lay-report-computational-design-of-optoelectric-materials&#34;&gt;Lay Report &amp;mdash; Computational Design of Optoelectric Materials&lt;/h2&gt;

&lt;!-- ^[Plain text only: maximum 3,500 characters (including spaces)] --&gt;

&lt;p&gt;Building the future will require new materials, materials that are lighter and
better, cheaper and with less environmental impact.
Most materials we use now were discovered and improved by long experiment, not
designed.
My research is in designing the materials of the future.&lt;/p&gt;

&lt;p&gt;Photovoltaics are one particular type of material I work on.
These are a beautifully simple engine for converting sunlight (photons) into
electricity (volts).
Sunlight is the only renewable energy source that is large enough to replace all
of humanity&amp;rsquo;s requirements, and is available to everyone.
Designing Photovoltaics is particularly difficult as the material must be both optically
and electrically active.&lt;/p&gt;

&lt;p&gt;Currently most photovoltaics are made out of silicon.
This material is abundant (sand is mainly silicon dioxide), but the
manufacturing process of turning it into a solar cell is expensive (with high
temperatures and vacuum processing in special clean rooms) and environmentally
costly (it requires a lot of strong chemicals to purify and treat the
silicon).
My work looks to design better and cheaper photovoltaic materials,
by solving equations with a computer.&lt;/p&gt;

&lt;p&gt;Everything that we see and touch and feel and hear is due to the structure of
the electrons in the matter around us.
It is this electronic structure that makes the material strong or weak,
transparent or opaque, insulate or conduct electricity.
The electrons in a material are very lightweight so they move quickly,
this means that they display very quantum mechanical behaviour.
The equations that describe this electronic structure, were discovered in the
1930s and are simple to write down.&lt;br /&gt;
Unfortunately we cannot solve these equations exactly.
Instead we use super computers to build an approximate solution for a small model system.
The main problem when solving these equations is that every single electron in
the system interacts with every other one.
Solving these equations is like trying to choose a restaurant with a large
crowd of people.
The more people the more difficult to consider everyone&amp;rsquo;s individual
preferences, and you end up somewhere that&amp;rsquo;s a bad choice for everyone.&lt;/p&gt;

&lt;p&gt;When we build these computer models correctly, we can start with an
arrangement of atoms that doesn&amp;rsquo;t exist (yet), and predict its properties, all
within the computer.
This is much cheaper and faster than making the material.
Validating these computer models against reality and understanding the limits
of the techniques available, is essential to be able to make genuine
predictions.
For this reason though I work entirely on a computer, I talk everyday with
experimentalists who make new materials and then measure their properties.
By comparing our measurements and calculations we can really begin to
understand how these new materials work, and this understanding can help us to
design better materials.
Theory and calculation enables us to design materials with specific
properties, so we no longer have to just hope to discover materials with these
properties by accident.
Working together, theory and calculation can suggest the direction for the next
step into the unknown, while experiment keeps the theory grounded in reality.&lt;/p&gt;

&lt;p&gt;Materials design will enable humanity to face the challenges of building the
future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mark Tuckerman talk: Free energy based structure prediction</title>
      <link>http://jarvist.github.io/post/2016-04-19-mark-tuckerman-talk-free-energy-structure-prediction/</link>
      <pubDate>Tue, 19 Apr 2016 14:44:34 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-04-19-mark-tuckerman-talk-free-energy-structure-prediction/</guid>
      <description>

&lt;p&gt;Mark Tuckerman (MET) visited London on the 31st March 2016, and gave
a highlight seminar to the TYC at UCL.
I had been really enjoying his recent (2010) Computational Stat Mech book [1].
I know very little about structure prediction, but it is of general and
captivating interest, and an essential step in truly predictive computational
materials science.
Here are a summary of my notes from his talk, written up mainly for my own
reference, and for clickable citations.&lt;/p&gt;

&lt;p&gt;A point Mark made at the start and repeatedly was that we need to go beyond the
static structure picture - we need the entropic contribution, and we therefore
need to be able to calculate free energies.&lt;/p&gt;

&lt;h2 id=&#34;small-molecular-crystals&#34;&gt;Small molecular crystals&lt;/h2&gt;

&lt;p&gt;The first area discussed was predicting structure of small molecular crystals,
the example for them was having taken part in the CCDC Blind Test [2], but
focusing on a single molecule &amp;amp; attempting to explore the polymorphs.
The motivation here is that for Pharma research, knowing the existence of
energetically accessible polymorphs is of utmost importance due to highly
varying bioavailability of different polymorphs.&lt;/p&gt;

&lt;p&gt;The method started off fairly standard. As general force fields are too coarse,
and quantum mechanical calculations too expensive, a customised force field was
developed. QC calculations on dimers were used to parameterise, with a fairly
normal &lt;code&gt;PBE0+TS; 6-311g**(d,p)&lt;/code&gt;.
25000 Unit cells were generated with &lt;code&gt;UPACK&lt;/code&gt;, a software package I had not
heard of, but which seems pretty extensive [3].&lt;/p&gt;

&lt;p&gt;MD (I think just vanilla) on the packed structures lead to trajectories where
interconversion from one structure to another could be seen. Eventually they
settled down to 50 (lowest energy?) structures, plotted on an energy vs.
density plot.&lt;br /&gt;
Their 4th lowest energy structure agreed with the &amp;lsquo;blind&amp;rsquo; experimental
structure.
Mark was more pleased with having found a lot of low lying polymorphs.&lt;/p&gt;

&lt;p&gt;So far so good for an interesting seminar, and a laudable result - but this is
where it got really interesting.&lt;/p&gt;

&lt;p&gt;Mark linked from structure prediction to protein folding via a 2004 PNAS [4],
which proposed that both problems are essentially the same.
You have a rough energy landscape, you need to determine the occupancy of the
basins.&lt;/p&gt;

&lt;h2 id=&#34;collective-variables&#34;&gt;Collective variables&lt;/h2&gt;

&lt;p&gt;To do this, Mark suggests targeting collective variables - something that
distinguishes different conformal states.
These are selected &amp;lsquo;by hand&amp;rsquo; with &amp;lsquo;insight&amp;rsquo; and &amp;lsquo;chemical intuition&amp;rsquo; to fit the
problem studied.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The most simple example are the Psi and Theta angles of the Ramachandran plot [5] for amino acid residues.&lt;/li&gt;
&lt;li&gt;For crystals you can take the unit cell vectors and stuff them into what Mark
referred to as the &lt;code&gt;h&lt;/code&gt; matrix.&lt;/li&gt;
&lt;li&gt;For packing, you can take angles and distances, or use &lt;code&gt;Q&lt;/code&gt;, &lt;code&gt;W&lt;/code&gt; Steinhardt
bond-order parameters.

&lt;ul&gt;
&lt;li&gt;[Incidentally, I recently learned thanks to another seminar that these
seemingly mystical parameters are really quite simple - they&amp;rsquo;re just
spherical harmonics!  You consider only even-l versions of these, making
them invariant under inversion. [6] ]&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;temperature-accelerated-md&#34;&gt;Temperature accelerated MD&lt;/h2&gt;

&lt;p&gt;Temperature accelerated MD was then introduced.
Mark described it as essentially being an additional (standard) equation of
motion being simultaneously solved, in the collective variables.
A very large fictitious mass is used for the collective-variable centre, and
a separate thermostat (~32000 K was an example).
This physically means that the collective variables have the energy to hop
potential barriers between minima, and the momentum to smoothly move between
them.
The large difference in mass allows for an adiabatic decoupling of the
Equations of Motion.&lt;/p&gt;

&lt;p&gt;I did not realise that temperature accelerated MD was this conceptually simple.&lt;/p&gt;

&lt;p&gt;Metadynamics is an alternative way to explore the free energy landscape, but
relies on the simulation dropping little Gaussians in the potential energy
where they are currently, so requires a certain amount of time to fill up the
basins and escape to the next one. To get the free energy, once you&amp;rsquo;ve filled
all the basins you invert the Gaussians and this gives you the free energy
surface.&lt;/p&gt;

&lt;h3 id=&#34;protein-folding-alanine-decamers-between-alpha-helix-and-beta-hairpin&#34;&gt;Protein folding: Alanine Decamers between alpha helix and beta hairpin&lt;/h3&gt;

&lt;p&gt;Accelerated MD on this as a model system (I think with the CHARMM forcefield),
with the Ramachandran variables (20 collective variables).
Running this produces lots of structures, with the transition paths identified [10].
Using a Berendsen thermostat with added noise [7], defining a path as the
collective variable, you can integrate along to get free energy.
This gives you a smooth energy along the coordinate, and thus a well found
value for the free energy difference.&lt;/p&gt;

&lt;p&gt;I found a 2014 YouTube video containing the MD, but the extraction of free
energy seems a bit different:
&lt;a href=&#34;https://youtu.be/WKpe8fzATr4?t=21m38s&#34;&gt;https://youtu.be/WKpe8fzATr4?t=21m38s&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;polymorphic-benzene&#34;&gt;Polymorphic benzene&lt;/h3&gt;

&lt;p&gt;Separately they studied polymorphs of benzene.
The &amp;lsquo;h&amp;rsquo; matrix (lattice basis) was explicitly evolved in the EoM, dragging
atoms instantly with it.
With benzene at 100K (atomic thermostat) and 32000 K (collective variable
thermostat), 5 ns of MD was sufficient for all free energies, 0.5 ns of MD
found all the polymorphs.&lt;/p&gt;

&lt;p&gt;This is explored in [8], and MET references thereafter.&lt;/p&gt;

&lt;h3 id=&#34;melting-copper&#34;&gt;Melting Copper&lt;/h3&gt;

&lt;p&gt;Melting Cu, with collective variables on the diagonal of &lt;code&gt;h&lt;/code&gt;; and
a Q4, Q6 spherical harmonic &amp;lsquo;bond order&amp;rsquo;.
The EAM potential was used.&lt;/p&gt;

&lt;p&gt;Here they looked at classical nuclear theory.
The simulations showed a more complex story - the hot solid had defects which
were highly mobile. Defects formed clusters to minimise their free energy&lt;/p&gt;

&lt;h3 id=&#34;navigating-on-a-high-dimensional-surface&#34;&gt;Navigating on a high dimensional surface&lt;/h3&gt;

&lt;p&gt;You can&amp;rsquo;t visualise the surface - it is too high in dimension. But you want to
see the &amp;lsquo;interesting&amp;rsquo; minima and saddle points.
You can use a Parrinello-group sketchmap [9], which appears to be a clustering
graph representation.
Here [11] they used these ideas, and the &lt;code&gt;START&lt;/code&gt; method where the free energy
gradient and the Hessian were constructed in terms of collective variables, to
give you the weakest eigenvector to walk along with steepest descents.&lt;/p&gt;

&lt;p&gt;Some very recent and unpublished data investigated Anthracene crystals,
defining the Euler angles (though a later figure mentioned an &amp;lsquo;absolute
quaternion&amp;rsquo;) and cell parameters as collective variables. They found the
experimental structure, and loads of near-energy polymorphs&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;It was an extremely thought provoking talk. The explanation of temperature
accelerated molecular dynamics was the first time that it made sense to me.
The power of integrating the EoM for a collective variable &amp;amp; so ride roughshod
across a rough potential energy landscape with the ability to extrapolate free
energies is clearly fantastically powerful.&lt;/p&gt;

&lt;p&gt;One bit of black magic that I do not understand, is where the force
acting on the collective variables comes from.
Some kind of potential defined in the collective variables? By direct coupling
between the atomistic positions and the collective variables?&lt;/p&gt;

&lt;p&gt;However, I felt that everything presented seemed a little clunky.
Certainly the science was fantastic, but every example seemed to have been set
up slightly differently and individually by the researchers.
There was no mention of these codes or methods being made available.&lt;/p&gt;

&lt;p&gt;One thing obviously missing from a scientific point of view was a algorithmic
way to define the collective variables, rather than relying on intuition.&lt;/p&gt;

&lt;p&gt;In a paper I&amp;rsquo;ve been reading recently [12], the authors of VoroTop introduce
a method to identify local structure independent of radial distribution
functions and bond orders. Instead they define the 3D Voronoi cell for individual
atoms, and then compare the isomorphism (or not!) of the 2D Schlegel diagram
(i.e. a planar graph of connectivity of the Voronoi vertices) to identify
topologically distinct local bonding.
I wonder if some ideas from here, could be borrowed and used to construct
collective variables automatically.&lt;/p&gt;

&lt;p&gt;Once you can identify the collective variables automatically, the exploration
of rough potential energy surfaces, while retaining the free-energy of
structures, will be practically pleasant.&lt;/p&gt;

&lt;p&gt;With a bit of Googling I found a Tuckerman slide deck from 2014 which
overlapped with this talk a fair bit:
&lt;a href=&#34;http://conference.mipt.ru/img/conference/material-design-2014/talks/Hybertsen-talk.pdf&#34;&gt;http://conference.mipt.ru/img/conference/material-design-2014/talks/Hybertsen-talk.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Mark has a Google Scholar page, for if you want to dig through more of his
literature [13].&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Mark E. Tuckerman (2010), Statistical Mechanics: Theory and Molecular
Simulation. Oxford Graduate Texts.
(&lt;a href=&#34;https://www.amazon.co.uk/Statistical-Mechanics-Molecular-Simulation-Graduate/dp/0198525265&#34;&gt;https://www.amazon.co.uk/Statistical-Mechanics-Molecular-Simulation-Graduate/dp/0198525265&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&#34;https://www.ccdc.cam.ac.uk/Community/initiatives/cspblindtests/&#34;&gt;https://www.ccdc.cam.ac.uk/Community/initiatives/cspblindtests/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&#34;http://www.crystal.chem.uu.nl/~vaneyck/upack.html&#34;&gt;http://www.crystal.chem.uu.nl/~vaneyck/upack.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4]
&amp;ldquo;Exercises in
prognostication: Crystal structures and protein folding&amp;rdquo;.
Jack D. Dunitz and Harold A. Scheraga (2004).
PNAS 40(101),
14309-14311. &lt;a href=&#34;http://dx.doi.org/10.1073/pnas.0405744101&#34;&gt;http://dx.doi.org/10.1073/pnas.0405744101&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&#34;https://en.wikipedia.org/wiki/Ramachandran_plot&#34;&gt;https://en.wikipedia.org/wiki/Ramachandran_plot&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] &amp;ldquo;Bond-orientational order in liquids and glasses&amp;rdquo;
Paul J. Steinhardt, David R. Nelson, and Marco Ronchetti (1983).
Phys. Rev. B 28, 784.
&lt;a href=&#34;http://dx.doi.org/10.1103/PhysRevB.28.784&#34;&gt;http://dx.doi.org/10.1103/PhysRevB.28.784&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[7]
&amp;ldquo;Canonical sampling through velocity rescaling&amp;rdquo;.
Giovanni Bussi, Davide Donadio and Michele Parrinello (2007).
J. Chem. Phys. 126, 014101 (2007); &lt;a href=&#34;http://dx.doi.org/10.1063/1.2408420&#34;&gt;http://dx.doi.org/10.1063/1.2408420&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[8]
&amp;ldquo;Temperature-Accelerated Method for Exploring Polymorphism in Molecular Crystals Based on Free Energy&amp;rdquo;
Tang-Qing Yu and Mark E. Tuckerman (2011).
Phys. Rev. Lett. 107, 015701;
&lt;a href=&#34;http://dx.doi.org/10.1103/PhysRevLett.107.015701&#34;&gt;http://dx.doi.org/10.1103/PhysRevLett.107.015701&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[9]
&amp;ldquo;Simplifying the representation of complex free-energy landscapes using
sketch-map&amp;rdquo;.
Michele Ceriotti, Gareth A. Tribello, and Michele Parrinello (2011).
PNAS 32(108), 13023-13028.
&lt;a href=&#34;http://dx.doi.org/10.1073/pnas.1108486108&#34;&gt;http://dx.doi.org/10.1073/pnas.1108486108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[10]
&amp;ldquo;Sampling saddle points on a free energy surface&amp;rdquo;
Amit Samanta, Ming Chen, Tang-Qing Yu, Mark Tuckerman and Weinan
J. Chem. Phys. 140, 164109 (2014); &lt;a href=&#34;http://dx.doi.org/10.1063/1.4869980&#34;&gt;http://dx.doi.org/10.1063/1.4869980&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[11]
&amp;ldquo;Locating landmarks on high-dimensional free energy surfaces&amp;rdquo;
Ming Chen, Tang-Qing Yu, and Mark E. Tuckerman (2015).
PNAS vol. 112 no. 11 (2015); &lt;a href=&#34;http://dx.doi.org/10.1073/pnas.1418241112&#34;&gt;http://dx.doi.org/10.1073/pnas.1418241112&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[12]
&amp;ldquo;Topological framework for local structure analysis in condensed matter&amp;rdquo;
Emanuel A. Lazar, Jian Han, and David J. Srolovitz (2015).
PNAS vol. 112 no. 43; &lt;a href=&#34;http://dx.doi.org/10.1073/pnas.1505788112&#34;&gt;http://dx.doi.org/10.1073/pnas.1505788112&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[13] Mark E. Tuckerman, Google Scholar.
&lt;a href=&#34;https://scholar.google.co.uk/citations?hl=en&amp;amp;user=w_7furwAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate&#34;&gt;https://scholar.google.co.uk/citations?hl=en&amp;amp;user=w_7furwAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Delta SCF: Calculating work functions of molecular electronic materials</title>
      <link>http://jarvist.github.io/post/2016-03-17-delta-scf/</link>
      <pubDate>Wed, 23 Mar 2016 14:44:34 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-03-17-delta-scf/</guid>
      <description>

&lt;p&gt;All modern functional electronic devices are made from semiconductors.
A semiconductor is a material with a moderate band gap.
But to turn this semiconductor into a device, you need to be able to
selectively inject and extract electrons from above and below this band gap,
forming selective contacts.&lt;/p&gt;

&lt;p&gt;The metrics we want to calculate are the Electron Affinity (energy gain by
adding an electron from infinite distance) and the Ionisation Potential (energy
required to remove an electron from the bulk to infinite distance).&lt;br /&gt;
In a metal there is no distinction between these values (the same energy state
is involved), and both are equivalent to the Work Function.&lt;/p&gt;

&lt;p&gt;When calculating electronic structure, in a periodic system (where the
electronic states are broadened bands) we talk of the Conduction Band Minimum
(CBM) and Valence Band Maximum (VBM); in a molecular system (where for
calculation we usually have an isolated molecule in vacuum) we talk in terms of
the Lowest Unoccupied Molecular Orbital (LUMO) and Highest Occupied Molecular
Orbital (HOMO).&lt;/p&gt;

&lt;p&gt;The difference (in energy) between CBM and VBM, or similar LUMO and HOMO, gives
us the Fundamental Gap.
In a periodic system, this fundamental gap is a good estimate for the optical
Band Gap of the material.
This is because the absorption of a photon generates very loosely (negligibly)
bound electron and hole states (the exciton).
In a molecular system, this difference between the Fundamental and Band Gap
(the exciton binding energy), can easily be 1 eV.
The excited state (exciton) involves wave functions that are highly localised.
The electron and hole are energetically bound; as there is large wavefunction
overlap, the exchange interaction means that Singlet and Triplet states exist,
and have different energies.
Methods that explicitly treat the electron-hole interaction (such as
Time-Dependent Density-Functional-Theory) are a much better estimate for the
band gap in such systems.&lt;/p&gt;

&lt;p&gt;But what are these orbital energies relative to?
The naive expectation would be to the vacuum energy.&lt;/p&gt;

&lt;p&gt;For a periodic calculation this can&amp;rsquo;t be, as there is no absolute reference in
the periodic summations used to get the electrostatic potential.
Often codes practically pin these values against the core states of the
composite atoms used in the pseudo potential - so they &amp;lsquo;look&amp;rsquo; about right, but
woe betide anyone using these as actual work functions!
However, you can define a &amp;lsquo;vacuum&amp;rsquo; region in your simulation where no electrons
are present and use the electrostatic potential in this region as the reference
for your bulk values.
My colleague Keith Butler has developed this method into a useful (and fun!)
code named MacroDensity ([1] - &lt;a href=&#34;https://github.com/WMD-group/MacroDensity&#34;&gt;https://github.com/WMD-group/MacroDensity&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;With non-periodic (molecular) calculations, you do have an absolute
reference - the vacuum is everywhere around you!
But are the electron eigenvalues (i.e. HOMO / LUMO) actually what you want?&lt;/p&gt;

&lt;p&gt;A key thing to remember is that the Density Functional Approximation is
guaranteed to give you one thing - total energy.
The Kohn-Sham eigenvectors [2] are auxiliary functions to enable the solving for
the total energy of the system, in particular by providing orbitals which can
be used to evaluate the kinetic energy of the electrons.
The debate about whether the Kohn-Sham eigenvalues have any greater meaning has
rumbled on for decades.
It has become an almost ecumenical matter.
It is usually referred to as &amp;ldquo;Koopmans&amp;rsquo; Theorem&amp;rdquo; in the literature, which
refers to the exact agreement in Hartree-Fock theory between the occupied
orbitals and the ionisation energies (energetic cost to remove an electron).
Depending on who you ask, this theory is correct for Hybrid Density Functional
Theory for: all occupied and unoccupied orbitals, just the occupied orbitals,
just the highest occupied orbital (HOMO).&lt;/p&gt;

&lt;p&gt;Certainly in my testing with organic electron materials and hybrid density
functionals, the HOMO often seems a good estimate for the ionisation potential.
The LUMO is often not even correlated with variations in electron affinity
(i.e. it is qualitatively and quantitatively wrong.)&lt;/p&gt;

&lt;p&gt;So if we don&amp;rsquo;t trust our single-electron eigenvalues, what can we do?&lt;/p&gt;

&lt;p&gt;A conceptually (and practically!) simple method is that of the &amp;lsquo;Delta SCF&amp;rsquo;.
The name is rather curious, but it seems to have stuck.
You calculate the total Self-Consistent-Field energy of a &lt;code&gt;N&lt;/code&gt; electron system,
and deduct the total energy of a &lt;code&gt;N+1&lt;/code&gt; (or &lt;code&gt;N-1&lt;/code&gt;) system.
This difference is the total energy upon adding (or removing) an electron, and
is therefore the Electron Affinity (or Ionisation Energy).
You do this at the geometry of the neutral molecule (apart from anything else,
this stops the difference in total energy requiring consideration of the
nuclear-nuclear repulsion which would change between two different geometries).&lt;/p&gt;

&lt;p&gt;As ever in electronic structure theory this method &amp;lsquo;weighs the admiral by weighing
the battleship with and without him on board&amp;rsquo;.
It is thus extremely important that errors in the two total energies are
carefully controlled.&lt;/p&gt;

&lt;p&gt;An alternative, which chemists seem to particularly like, is to estimate the
Ionisation Potential from the HOMO of a DFT calculation, and then add on the
Band Gap of the material via a TDDFT calculation to get the Electron Affinity.
It is somewhat surprising that this often gives a good agreement to the solid
state energies.
One possibility is that it represents some kind of &amp;lsquo;Pauling point&amp;rsquo; (correct for
the wrong reasons), that the exciton binding energy (and assorted systematic
errors) in the TDDFT is somehow compensating for the delocalisation of the
wavefunction in a solid, and the effect of the dielectric environment.
This method I used in a 2009 study of various fullerene adduct isomers [3].
Later work (alas unpublished) on a much wider range of fullerenes suggested
that the major variation in the Electron Affinity (~LUMO) was due to there
being a constant Fundamental Gap between it and the HOMO.&lt;/p&gt;

&lt;p&gt;Mark Casida (yes, that Casida!) has some interesting slides on why there should
be such an agreement between TDDFT and Delta-SCF [4].&lt;/p&gt;

&lt;h2 id=&#34;doing-it-by-hand-with-gaussian&#34;&gt;Doing it by hand with Gaussian&lt;/h2&gt;

&lt;p&gt;So you want to do a Delta-SCF calculation for a molecule-in-vacuum with Gaussian.
You start with a carefully converged single point calculation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#p sp b3lyp/6-31g* SCF(Tight,Conver=8) Integral(Grid=UltraFine)

Neutral calculation - for Delta-SCF.

0 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A standard, single point, energy calculation, with upped convergence &amp;amp; the
two-electron integrals calculated on an ultrafine grid. The &lt;code&gt;0 1&lt;/code&gt; is the
&lt;code&gt;Charge Multiplicity&lt;/code&gt;. This is a Neutral (Charge=0) calculation in a spin Singlet
(Multiplicity=1) configuration.&lt;/p&gt;

&lt;p&gt;We have made the convergence tighter (i.e. it will do more SCF cycles to get
a lower noise answer) on an increased fidelity integration grid. See:
&lt;a href=&#34;http://www.gaussian.com/g_tech/g_ur/k_integral.htm&#34;&gt;http://www.gaussian.com/g_tech/g_ur/k_integral.htm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And now the same structure (no further nuclear relaxation), as a charged doublet.
If you want the energy of adding an electron to the &amp;lsquo;LUMO&amp;rsquo; (the electron
affinity), you compare the neutral energy to the system with an added electron
(Charge=-1, the Anion). This is comparing &lt;code&gt;N&lt;/code&gt; to &lt;code&gt;N+1&lt;/code&gt; electrons.
For a Delta-SCF calculation of the Ionisation Potential (IP), you compare to
the &lt;code&gt;N-1&lt;/code&gt; electron case, the cation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#p sp b3lyp/6-31g* SCF(Tight,Conver=8) Integral(Grid=UltraFine)

Anion calculation - for Delta-SCF of the LUMO / Electron Affinity.

-1 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that is it. Now run these jobs, calculate the difference of the total SCF
energy between them, and you have your estimate of the Ionisation Potential or
the Electron Affinity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh
neutral=` grep &amp;quot;SCF Done&amp;quot; &amp;quot;${1}&amp;quot; | awk &#39;{print $5}&#39; `
charged=` grep &amp;quot;SCF Done&amp;quot; &amp;quot;${2}&amp;quot; | awk &#39;{print $5}&#39; `

echo -n &amp;quot;${1}    &amp;quot;
echo -n &amp;quot;($neutral - $charged ) * 27.211&amp;quot; | bc -l
echo &amp;quot;  eV&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;scripts-for-gaussian&#34;&gt;Scripts for Gaussian&lt;/h2&gt;

&lt;p&gt;After doing this for the n&amp;rsquo;th time as part of this post, I thought I should sit
down and write an all-singing script for automating the process.&lt;/p&gt;

&lt;p&gt;The files are available as a Github Gist
(&lt;a href=&#34;https://gist.github.com/jarvist/616c8c7c3ea576d03d73&#34;&gt;https://gist.github.com/jarvist/616c8c7c3ea576d03d73&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;From Gaussian .log outputs with optimised structures, generate &lt;code&gt;.xyz&lt;/code&gt; files of
the coordinates with &lt;code&gt;&amp;gt;extract_list_geoms.sh *.log&lt;/code&gt;.
Then generate your Delta-SCF &lt;code&gt;.com&lt;/code&gt; Gaussian input files,
&lt;code&gt;&amp;gt;g09_xyz_to_delta_SCF_coms_standalone.sh *.xyz&lt;/code&gt;.
Run the resulting &lt;code&gt;.com&lt;/code&gt; files through Gaussian.
Analyse the outputs with &lt;code&gt;&amp;gt; delta_SCF_extract_values.sh&lt;/code&gt;.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/jarvist/616c8c7c3ea576d03d73.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Macrodensity - codes to read VASP LOCPOT files and calculate electrostatic
potential derived quantities (&lt;a href=&#34;https://github.com/WMD-group/MacroDensity&#34;&gt;https://github.com/WMD-group/MacroDensity&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;[2] Kohn, Walter; Sham, Lu Jeu (1965). &amp;ldquo;Self-Consistent Equations Including
Exchange and Correlation Effects&amp;rdquo;. Physical Review 140 (4A): A1133–A1138 (&lt;a href=&#34;http://dx.doi.org/10.1103/PhysRev.140.A1133&#34;&gt;http://dx.doi.org/10.1103/PhysRev.140.A1133&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;[3] Frost, J. M., Faist, M. A. and Nelson, J. (2010), Energetic Disorder in
Higher Fullerene Adducts: A Quantum Chemical and Voltammetric Study. Adv.
Mater., 22: 4881–4884. &lt;a href=&#34;http://dx.doi.org/10.1002/adma.201002189&#34;&gt;http://dx.doi.org/10.1002/adma.201002189&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] Mark Casida - Reconciling Delta-SCF and TDDFT, Transparencies from a talk, 1999
(&lt;a href=&#34;http://online.kitp.ucsb.edu/online/tddft-c99/casida/oh/01.html&#34;&gt;http://online.kitp.ucsb.edu/online/tddft-c99/casida/oh/01.html&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello HUGO!</title>
      <link>http://jarvist.github.io/post/2016-03-11-hello-hugo/</link>
      <pubDate>Fri, 11 Mar 2016 22:44:34 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/2016-03-11-hello-hugo/</guid>
      <description>&lt;p&gt;This blog used to be on wordpress, at
&lt;a href=&#34;https://jarvistmoorefrost.wordpress.com&#34;&gt;https://jarvistmoorefrost.wordpress.com&lt;/a&gt;.
( There are a few comments by other people scattered amongst those posts, I&amp;rsquo;m
not sure how to best transfer / archive these. )&lt;/p&gt;

&lt;p&gt;Files were extracted to a plain text Markdown
format, and are now published with &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; with the
&lt;code&gt;nofancy&lt;/code&gt; theme (slightly tweaked). I moved this blog from wordpress as I had
grown irritated with the editing experience, and I hope that being able to edit
and push from the command line would get me blogging more regularly.&lt;/p&gt;

&lt;p&gt;Time will see.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Talks and Seminars at Bath University</title>
      <link>http://jarvist.github.io/post/2015-12-08-talks-and-seminars-at-bath-university/</link>
      <pubDate>Tue, 08 Dec 2015 14:16:34 +0100</pubDate>
      
      <guid>http://jarvist.github.io/post/2015-12-08-talks-and-seminars-at-bath-university/</guid>
      <description>&lt;p&gt;There are a number of groups at Bath University doing work of interest to
Condensed Matter Theorists. This is just a quick set of &amp;lsquo;hot links&amp;rsquo; to the
individual seminar sites + pages. It is not intended to be exhaustive or
complete, but I try and see what&amp;rsquo;s on at all of these events for every week.&lt;/p&gt;

&lt;p&gt;Physics: Theory group seminars: &lt;a href=&#34;http://people.bath.ac.uk/rj248/theory_seminars.html&#34;&gt;http://people.bath.ac.uk/rj248/theory_seminars.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Maths: General colloquium, Landscapes in Mathematical Sciences: &lt;a href=&#34;http://people.bath.ac.uk/masgks/Landscapes/&#34;&gt;http://people.bath.ac.uk/masgks/Landscapes/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Maths: Numerical Analysis group seminars: &lt;a href=&#34;http://people.bath.ac.uk/em459/NASeminar/naseminar.html&#34;&gt;http://people.bath.ac.uk/em459/NASeminar/naseminar.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Physics: Nanoseminars: &lt;a href=&#34;https://wiki.bath.ac.uk/pages/viewpage.action?pageId=75175127&#34;&gt;https://wiki.bath.ac.uk/pages/viewpage.action?pageId=75175127&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Embarrassing embarrassingly parallel</title>
      <link>http://jarvist.github.io/post/embarrassing-embarrassingly-parallelism/</link>
      <pubDate>Fri, 22 May 2015 21:03:00 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/embarrassing-embarrassingly-parallelism/</guid>
      <description>&lt;p&gt;I gave up OPENMP&amp;rsquo;ing my Monte Carlo code about a year ago. I was trying to do it at the level of MC moves, and there are massive issues here in that the different threads are trying to sample and update the same simulation space - leading to segfaults as the variables crash into one another.&lt;/p&gt;

&lt;p&gt;One method I&amp;rsquo;ve seen used in the literature is domain decomposition - where each thread runs MC on a segment of the simulation volume. This is quite a headache to set up, and then you have issues about simultaneous updates, and the inability to exchange particles / states across the boundaries. All scary issues.&lt;/p&gt;

&lt;p&gt;So I gave up. I am not a computer scientist. I could not understand even the terms of reference; Lambda calculus reductions and all that jazz. In Simon Peyton Jones&amp;rsquo; terms, &amp;ldquo;I am a worm.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;I revisited it this evening, with the intention of seeing whether I could separate the thread of the random number generator at least. However, it instantaneously struct me what I should do. Each MC-move attempt calls &amp;lsquo;site-energy&amp;rsquo; with the test move which has a set of for loops evaluating over nearby space (i.e. with a cutoff) to get a total energy change for the test move.
The change in energy variable &amp;lsquo;dE&amp;rsquo; is a natural reduction vector, none of this modifies the simulation volume, and in a production run where you are integrating out a large volume of space for accurate energies - the majority of computer time is spend in these for loops.&lt;/p&gt;

&lt;p&gt;One: &lt;code&gt;#pragma omp parallel for reduction(+:dE)&lt;/code&gt; before the start of the for-loop nest; and a recompile with &lt;code&gt;-fopenmp&lt;/code&gt;, and it now maxes out the 4 hyperthreaded cores on my laptop.&lt;/p&gt;

&lt;p&gt;Scaling will be more limited on bigger machines, and increase in speed will only be seen where this energy summation, rather than the single-core modifications to the simulation volume and random number generator, dominate the CPU required.&lt;/p&gt;

&lt;p&gt;But still. Embarrassing embarrassingly parallel, because I could have and should have seen this a year ago!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Organising computational job workflow, as you go: freck</title>
      <link>http://jarvist.github.io/post/organising-computational-job-workflow-as-you-go-freck/</link>
      <pubDate>Sun, 26 Apr 2015 16:15:52 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/organising-computational-job-workflow-as-you-go-freck/</guid>
      <description>&lt;p&gt;The workflow in computational materials modelling is often highly complex, and bespoke to the particular calculations you are doing. The flow is highly derivative (results of later jobs depend on work on prior jobs), but can also be quite chaotic and multiply branching. Unsurprisingly, your files easily end up very messy, with significant confusion about what steps were required to get to the present working setup.&lt;/p&gt;

&lt;p&gt;Version control is an absolute godsend, being able to flow down the list settings changes is extremely useful, and then being able to simply open the Git archive on GitHub as a way of archiving your research data is fantastic. However, this still leaves problems to be solved - the main one is actually constructing the folder structure sensibly. (A lesser issue is that intermediate and binary files in electronic structure calculations can be enormous (&amp;gt;multi gigabyte) and so far too large for git.)&lt;/p&gt;

&lt;p&gt;To aid this I&amp;rsquo;ve written a very lightweight shell script called &amp;lsquo;freck&amp;rsquo; (to move swiftly or nimbly, an obsolete English word). Each time this is run in a working directory, it generates a folder named 0001-, 0002- etc. with a user-requested file name, and then moves all the present working files into that directory. It also saves a &amp;lsquo;breadcrumb&amp;rsquo; file with information about when and where you are writing this. I would like it to also add information extracted from your present history (i.e. all the commands you have used to work on the data), but the problem is that the shell script runs within its own shell, and it&amp;rsquo;s not obvious how to easily or portably access this.
(history &amp;gt; history.log ; is very quick to run though)&lt;/p&gt;

&lt;p&gt;The suggestion would be that you then typically run a &amp;lsquo;git add&amp;rsquo; on the small input / output files, and commit these to a repository with a sensible commit history.
Then copy the necessary files to continue your job into the PWD, and continue work.
But it&amp;rsquo;s flexible enough that you can also just use this to separate your work when running on a cluster.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m sure I&amp;rsquo;m not the only one who&amp;rsquo;s ended up with a folder structure that ends up looking hellishly like this:-
~/PROJECT_FOO/geom_opt/geom_opt_restart/geom_opt_restart_higher_convergence/moar_kpoints/cation_geom/cation_geom_restart/frequency_calc/ etc.&lt;/p&gt;

&lt;p&gt;Instead you end up with something much more sensible, time ordered and single-depthh: &lt;a href=&#34;https://github.com/jarvist/CDFT-C2H4&#34;&gt;https://github.com/jarvist/CDFT-C2H4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Anyhow, check it out here + I&amp;rsquo;m always interested in all + any feedback!
&lt;a href=&#34;https://github.com/jarvist/freck&#34;&gt;https://github.com/jarvist/freck&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing scientific papers</title>
      <link>http://jarvist.github.io/post/writing-scientific-papers/</link>
      <pubDate>Sun, 01 Mar 2015 22:44:00 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/writing-scientific-papers/</guid>
      <description>

&lt;p&gt;(Updated 2016-03-12 to re-add the links)&lt;/p&gt;

&lt;p&gt;I am probably the last person you would want to consult on tips to write
a scientific publication. I&amp;rsquo;m slow, I procrastinate, my English is not the
best, much work lies on the cutting room floor - skeletons of half assembled
papers. Still, &amp;lsquo;that which we are, we are&amp;rsquo;, though my skills are lacking I&amp;rsquo;m
very interested in improving, and certainly enjoy reading a well written paper.&lt;/p&gt;

&lt;p&gt;It is an unfortunate fact that the quality of scientific writing is
decreasing as a function of time.
Some of this can be explained by the laudable continuing expansion of
scienitific research across the world resulting in a greater number of authors
writing English as an additional language.
I believe the major reason stems from the unrelenting pressure to publish.
Many more papers are written, yet there are still only the same number of days
in the year.
With these publication metrics deciding so much of our future careers (and thus
lives), there is also enormous pressure to &amp;lsquo;glam up&amp;rsquo; work and oversell, as well
as to &amp;lsquo;salami slice&amp;rsquo; and represent work that belongs together in one
paper in many.&lt;/p&gt;

&lt;p&gt;It used to be that scientists would work continuously on a problem, and then
publish when a &amp;lsquo;breakthrough&amp;rsquo; had been made.
To be honest I think we would have a better scientific corpus if this was still
the case - careful work on a hard problem for a few years until we gain some
traction, then write it up for the benefit of anyone who could take it
elsewhere.&lt;/p&gt;

&lt;p&gt;(Along these lines, Ross McKenzie has a recent blog post &amp;lsquo;&lt;a href=&#34;http://condensedconcepts.blogspot.co.uk/2015/02/in-praise-of-modest-goals.html&#34;&gt;In praise of modest
goals&lt;/a&gt;&amp;rsquo;.)&lt;/p&gt;

&lt;p&gt;So the first thing to do when writing is to overcome the cynicism!
When I get particular disaffected I return to Simon Peyton Jones&amp;rsquo; talk on &lt;a href=&#34;https://www.youtube.com/watch?v=g3dkRsTqdDA&#34;&gt;how
to write a great research paper&lt;/a&gt;
. His enthusiasm and motivation is infectious. I am a worm. A worm with
a infectious mind virus, and that is good.&lt;/p&gt;

&lt;p&gt;Sabine Hossenfelder wrote a useful blog post on &lt;a href=&#34;http://backreaction.blogspot.co.uk/2015/01/how-to-write-your-first-scientific-paper.html&#34;&gt;How to write your first
scientific
paper&lt;/a&gt;,
this covers the construction and sectioning of a physics paper.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve personally found the Penguin Writer&amp;rsquo;s Manual very useful for the nitty
gritty of &amp;lsquo;that&amp;rsquo; vs &amp;lsquo;which&amp;rsquo;. I&amp;rsquo;ve also read Strunk and White (The elements of
style), though I&amp;rsquo;m not sure how much I took from it. The &lt;a href=&#34;http://backreaction.blogspot.co.uk/2015/01/how-to-write-your-first-scientific-paper.html&#34;&gt;economist style
guide&lt;/a&gt;
(available online) is also very useful as a reference.
(2016 update: Steven Pinker&amp;rsquo;s &amp;lsquo;The Sense of Style&amp;rsquo; is fantastic. Dispels a lot
of prescriptive myths, but also teaches how to analyse your sentences and
identify clumsy phrases.)&lt;/p&gt;

&lt;p&gt;I much prefer to write with Latex. Sometimes I first go via Markdown (a
lightweight markup language that looks a lot like how you would naturally
format a text email), so I don&amp;rsquo;t need to bother with thinking about the Latex
commands when forming a text, and then convert to Latex (with pandoc) for
inclusions of figures &amp;amp; all the revisions that incur thereafter. The whole
project I put within a &amp;lsquo;git&amp;rsquo; repository and so have version control,
effectively offsite backup (to Github / Bitbucket). To get the diffs to work
well with the files, it&amp;rsquo;s easiest to add a newline after the end of every
sentence (I usually hard-break my lines at 80 chars as I write in Vim).&lt;/p&gt;

&lt;p&gt;I have contributed to papers in Microsoft Word (usually originating with
collaborators). It works OK, and the track changes / comment tool can be really
useful, though a distressing number of collaborators seem to send you back
a &amp;lsquo;clean&amp;rsquo; document with the tracking dropped. Whether that&amp;rsquo;s due to ignorance
of the tools, compatibility with different versions of Word, or an attempt to
bury any information about which of your changes they reverted, I do not know.
Certainly it makes me respect them less both academically and professionally.
It is most incredibly frustrating to be editing a sentence, not sure
whether you&amp;rsquo;re applying the same change again, undoing an important correction
or what.&lt;/p&gt;

&lt;p&gt;I typically plot data in GNUPLOT or XMGRACE, sometimes also in Python&amp;rsquo;s
Matplotlib (though this is much less deterministic - the output depends on the
specific version you have installed, and it can be extremely frustrating to
reproduce a tweaked diagram). I&amp;rsquo;ve found some useful websites on tips + tricks
for plotting, useful beyond an immediate answer to resolving a problem.&lt;/p&gt;

&lt;h3 id=&#34;useful-general-resources&#34;&gt;Useful general resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Simon Peyton Jones talk &lt;a href=&#34;https://www.youtube.com/watch?v=g3dkRsTqdDA&#34;&gt;https://www.youtube.com/watch?v=g3dkRsTqdDA&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Hacker News discussion &lt;a href=&#34;https://news.ycombinator.com/item?id=6989806&#34;&gt;https://news.ycombinator.com/item?id=6989806&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Sabine Hossenfelder blogpost
&lt;a href=&#34;http://backreaction.blogspot.co.uk/2015/01/how-to-write-your-first-scientific-paper.html&#34;&gt;http://backreaction.blogspot.co.uk/2015/01/how-to-write-your-first-scientific-paper.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Researcher&amp;rsquo;s Bible
&lt;a href=&#34;http://homepages.inf.ed.ac.uk/bundy/how-tos/resbible.html&#34;&gt;http://homepages.inf.ed.ac.uk/bundy/how-tos/resbible.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Economist - Style Guide &lt;a href=&#34;http://www.economist.com/styleguide/introduction&#34;&gt;http://www.economist.com/styleguide/introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;colour&#34;&gt;Colour&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;IBM paper &amp;ldquo;Why should engineers and scientists be worried about color?&amp;rdquo;
&lt;a href=&#34;http://www.research.ibm.com/people/l/lloydt/color/color.HTM&#34;&gt;http://www.research.ibm.com/people/l/lloydt/color/color.HTM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adobe&amp;rsquo;s Color CC &lt;a href=&#34;https://color.adobe.com/explore/most-popular/?time=all&#34;&gt;https://color.adobe.com/explore/most-popular/?time=all&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TIGERcolor, Introduction to color theory
&lt;a href=&#34;http://www.tigercolor.com/color-lab/color-theory/color-theory-intro.htm&#34;&gt;http://www.tigercolor.com/color-lab/color-theory/color-theory-intro.htm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Smashing Magazine, Color theory for designers
&lt;a href=&#34;https://www.smashingmagazine.com/2010/02/color-theory-for-designer-part-3-creating-your-own-color-palettes/&#34;&gt;https://www.smashingmagazine.com/2010/02/color-theory-for-designer-part-3-creating-your-own-color-palettes/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Colorbrewer &lt;a href=&#34;http://colorbrewer2.org/&#34;&gt;http://colorbrewer2.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;writing&#34;&gt;Writing&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;20 Obsolete English Words
&lt;a href=&#34;http://matadornetwork.com/abroad/20-obsolete-english-words-that-should-make-a-comeback/&#34;&gt;http://matadornetwork.com/abroad/20-obsolete-english-words-that-should-make-a-comeback/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;University of Manchester academic phrasebank &lt;a href=&#34;http://www.phrasebank.manchester.ac.uk/&#34;&gt;http://www.phrasebank.manchester.ac.uk/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Uni of Illinois, Captilisation and dashes in Physics (PDF)
&lt;a href=&#34;http://www.nt.ntnu.no/users/haugwarb/Misc/capitalization.pdf&#34;&gt;http://www.nt.ntnu.no/users/haugwarb/Misc/capitalization.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;David Marsh, 10 grammar rules to forget
&lt;a href=&#34;https://www.theguardian.com/science/2013/sep/30/10-grammar-rules-you-can-forget&#34;&gt;https://www.theguardian.com/science/2013/sep/30/10-grammar-rules-you-can-forget&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;plotting&#34;&gt;Plotting&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Xmgrace tips &lt;a href=&#34;http://lptms.u-psud.fr/wiki/index.php/Tips_for_Xmgrace&#34;&gt;http://lptms.u-psud.fr/wiki/index.php/Tips_for_Xmgrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A Grace/Inkscape workflow
&lt;a href=&#34;https://sites.google.com/site/patrickbwarren/beautiful-figures&#34;&gt;https://sites.google.com/site/patrickbwarren/beautiful-figures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Grace Forum &lt;a href=&#34;http://plasma-gate.weizmann.ac.il/Grace/phpbb/&#34;&gt;http://plasma-gate.weizmann.ac.il/Grace/phpbb/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gnuplot Tricks &lt;a href=&#34;http://gnuplot-tricks.blogspot.co.uk/&#34;&gt;http://gnuplot-tricks.blogspot.co.uk/&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Publication quality example
&lt;a href=&#34;http://gnuplot-tricks.blogspot.co.uk/2009/05/gnuplot-tricks-many-say-that-it-is.html&#34;&gt;http://gnuplot-tricks.blogspot.co.uk/2009/05/gnuplot-tricks-many-say-that-it-is.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Gnuplotting &lt;a href=&#34;http://www.gnuplotting.org/&#34;&gt;http://www.gnuplotting.org/&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Output terminals &lt;a href=&#34;http://www.gnuplotting.org/output-terminals/&#34;&gt;http://www.gnuplotting.org/output-terminals/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;gnuplot-colorbrewer &lt;a href=&#34;https://github.com/aschn/gnuplot-colorbrewer&#34;&gt;https://github.com/aschn/gnuplot-colorbrewer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;git-latex-markdown&#34;&gt;Git / Latex / Markdown&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Word by word diffs in Git
&lt;a href=&#34;https://idnotfound.wordpress.com/2009/05/09/word-by-word-diffs-in-git/&#34;&gt;https://idnotfound.wordpress.com/2009/05/09/word-by-word-diffs-in-git/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A call for scholarly markdown
&lt;a href=&#34;http://blogs.plos.org/mfenner/2012/12/13/a-call-for-scholarly-markdown/&#34;&gt;http://blogs.plos.org/mfenner/2012/12/13/a-call-for-scholarly-markdown/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CodeCogs LaTeX equation editor (useful for talks not in LaTeX Beamer!)
&lt;a href=&#34;http://www.codecogs.com/latex/eqneditor.php&#34;&gt;http://www.codecogs.com/latex/eqneditor.php&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Detexify - draw a symbol, find the Latex
&lt;a href=&#34;http://detexify.kirelabs.org/classify.html&#34;&gt;http://detexify.kirelabs.org/classify.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LaTeX Templates &lt;a href=&#34;http://www.latextemplates.com/&#34;&gt;http://www.latextemplates.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TikZ example &lt;a href=&#34;http://www.texample.net/tikz/examples/membrane-surface/&#34;&gt;http://www.texample.net/tikz/examples/membrane-surface/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Top four LaTeX mistakes
&lt;a href=&#34;http://www.johndcook.com/blog/2010/02/15/top-latex-mistakes/&#34;&gt;http://www.johndcook.com/blog/2010/02/15/top-latex-mistakes/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Precise positioning in LaTeX Beamer
&lt;a href=&#34;http://blogs.helsinki.fi/smsiltan/2012/10/12/precise-positioning-in-latex-beamer/&#34;&gt;http://blogs.helsinki.fi/smsiltan/2012/10/12/precise-positioning-in-latex-beamer/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Papercore summaries
&lt;a href=&#34;http://papercore.org/summaries&#34;&gt;http://papercore.org/summaries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Making a poster with Inkscape
&lt;a href=&#34;http://blog.felixbreuer.net/2010/10/24/poster.html&#34;&gt;http://blog.felixbreuer.net/2010/10/24/poster.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ambient-music-for-headphones-in-noisy-offices&#34;&gt;Ambient music for headphones in noisy offices&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Music to let you concentrate &lt;a href=&#34;https://news.ycombinator.com/item?id=5872414&#34;&gt;https://news.ycombinator.com/item?id=5872414&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Headphone Commute - electronic, ambient &lt;a href=&#34;http://reviews.headphonecommute.com/&#34;&gt;http://reviews.headphonecommute.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Hex Grids</title>
      <link>http://jarvist.github.io/post/hex-grids/</link>
      <pubDate>Sun, 25 Jan 2015 23:06:52 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/hex-grids/</guid>
      <description>&lt;p&gt;Solid state materials pack together in a myriad of ways. The crystal structures are typically referred to with the name of the archetype compound. This ranges from fairly common English words such as &amp;lsquo;diamond&amp;rsquo; and &amp;lsquo;rock-salt&amp;rsquo; to, &amp;lsquo;zinc-blend&amp;rsquo; &amp;lsquo;wurtzite&amp;rsquo; and, of course, &amp;lsquo;perovskite&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;The atomic packing within these structures is fully described by their space-group, of which there are 230 to choose from. These space groups take the crystallographic (periodic structure) compatible point groups, and combine them with different possible lattice vectors.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://img.chem.ucl.ac.uk/sgp/large/sgp.htm&#34;&gt;http://img.chem.ucl.ac.uk/sgp/large/sgp.htm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some structures are fiendishly complicated, others are effectively cubic grids (perhaps with lattice vectors which are neither orthogonal nor equal in length). Even very complicated structures often have a sub lattice which packs cubically, or with hexagonal close packing.&lt;/p&gt;

&lt;p&gt;One of the perhaps surprising things is that hexagonal packing and cubic packing are extremely similar to one other - in particular cubic (BCC and FCC) and hexagonal close packing both have a coordination number of 12. Each sphere (atom) has 12 nearest neighbours.&lt;/p&gt;

&lt;p&gt;This is very useful, when you are building a computer model for a large structure. You can store the data about site occupancy in a simple array[][][], and calculate various necessary metrics (in particular real space distance vectors) via simple (i.e. free, in terms of computer time) arithmetic.&lt;/p&gt;

&lt;p&gt;I came across an article on hexagonal grids today; much of it was startling familiar, but in that way that it was giving you a framework and lexicon for understanding for what you&amp;rsquo;d hacked together with a partial glimpse of true understanding.&lt;/p&gt;

&lt;p&gt;(It&amp;rsquo;s written from the perspective of a games developer, but it&amp;rsquo;s directly applicable to scientific computation - just don&amp;rsquo;t tell the Research Councils how similar our austere science is to a game engine!)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.redblobgames.com/grids/hexagons/&#34;&gt;http://www.redblobgames.com/grids/hexagons/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;via HN discussion &lt;a href=&#34;https://news.ycombinator.com/item?id=8941588&#34;&gt;https://news.ycombinator.com/item?id=8941588&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snippet: SSH at Bath Uni</title>
      <link>http://jarvist.github.io/post/snippet-ssh-at-bath-uni/</link>
      <pubDate>Fri, 09 Jan 2015 14:36:35 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/snippet-ssh-at-bath-uni/</guid>
      <description>&lt;p&gt;I polished some slides I gave at our group meeting last summer, on using &amp;lsquo;ssh&amp;rsquo; proficiently at Bath university. I thought they may be of use to other&amp;rsquo;s, so published them online.&lt;/p&gt;

&lt;p&gt;They mainly cover the setting up of a ssh-config (the examples are probably useful for most people that use HPC facilities), and tunneling via the LCPU facility (fairly Bath specific, though other academic institutes might offer a similar unix machine in a DMZ to bounce through).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1OhQL_P5VT_467JhfcCVCFSmryZ0UoQkm_QzGTLNb7bU/pub?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34;&gt;Google Present Slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jarvist/filthy-dotfiles/blob/master/ssh-config&#34;&gt;https://github.com/jarvist/filthy-dotfiles/blob/master/ssh-config&lt;/a&gt; - my ssh-config, with Bath (&amp;amp; jarvist!) specific settings.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snippet: New Julia paper from the developers</title>
      <link>http://jarvist.github.io/post/snippet-new-julia-paper-from-the-developers/</link>
      <pubDate>Sat, 08 Nov 2014 13:32:50 +0000</pubDate>
      
      <guid>http://jarvist.github.io/post/snippet-new-julia-paper-from-the-developers/</guid>
      <description>&lt;p&gt;Looks to be a great reference, with plenty of code snippets getting bits of numerical methods working, finishing on the random-matrix semicircle theory, with @parallel speedup! Wish this was around when I was figuring out my little toy model&amp;hellip; &lt;a href=&#34;https://github.com/jarvist/LongSnakeMoan/blob/master/Sturm-DoS/Sturm_Drang.jl&#34;&gt;https://github.com/jarvist/LongSnakeMoan/blob/master/Sturm-DoS/Sturm_Drang.jl&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/1411.1607&#34;&gt;http://arxiv.org/abs/1411.1607&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;via the ever useful, if distracting, Hacker News:
&lt;a href=&#34;https://news.ycombinator.com/item?id=8576411&#34;&gt;https://news.ycombinator.com/item?id=8576411&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>